{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b5225f-2663-4949-9217-f643d0227217",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8427c303-bf31-4849-8910-0cb9f637e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_to_tags(data, separator='\\002'):\n",
    "    def parse_bio_labels(bio_labels):\n",
    "        entities = []\n",
    "        current_entity = None\n",
    "        \n",
    "        for i, label in enumerate(bio_labels):\n",
    "            if label == 'O':\n",
    "                if current_entity is not None:\n",
    "                    entities.append(current_entity)\n",
    "                    current_entity = None\n",
    "                continue\n",
    "            \n",
    "            # Correctly parse entity_type-B/I format\n",
    "            parts = label.split('-')\n",
    "            if len(parts) != 2:\n",
    "                continue  # Skip invalid labels\n",
    "            \n",
    "            e_type, prefix = parts  # Format: disaster-B â†’ e_type=disaster, prefix=B\n",
    "            \n",
    "            if prefix == 'B':\n",
    "                if current_entity is not None:\n",
    "                    entities.append(current_entity)\n",
    "                current_entity = {\n",
    "                    'start': i,\n",
    "                    'end': i,\n",
    "                    'type': e_type\n",
    "                }\n",
    "            elif prefix == 'I':\n",
    "                if current_entity and current_entity['type'] == e_type:\n",
    "                    current_entity['end'] = i\n",
    "                else:\n",
    "                    # Treat I tag as independent B tag when no corresponding B tag exists\n",
    "                    if current_entity is not None:\n",
    "                        entities.append(current_entity)\n",
    "                    current_entity = {\n",
    "                        'start': i,\n",
    "                        'end': i,\n",
    "                        'type': e_type\n",
    "                    }\n",
    "        \n",
    "        if current_entity is not None:\n",
    "            entities.append(current_entity)\n",
    "        \n",
    "        return entities\n",
    "\n",
    "    for item in data:\n",
    "        input_str = item.get('input', '')\n",
    "        bio_str = item.get('label_BIO', '')\n",
    "        \n",
    "        if not input_str or not bio_str:\n",
    "            continue\n",
    "        \n",
    "        bio_labels = bio_str.split(separator)\n",
    "        if len(bio_labels) != len(input_str):\n",
    "            continue  # Skip when lengths don't match\n",
    "        \n",
    "        entities = parse_bio_labels(bio_labels)\n",
    "        # Insert in reverse start order to avoid tag position shifting\n",
    "        sorted_entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
    "        \n",
    "        chars = list(input_str)\n",
    "        for ent in sorted_entities:\n",
    "            start = ent['start']\n",
    "            end = ent['end'] + 1  # Slice includes up to end-1\n",
    "            e_type = ent['type']\n",
    "            \n",
    "            # Insert closing tag\n",
    "            if end <= len(chars):\n",
    "                chars.insert(end, f'</{e_type}>')\n",
    "            else:\n",
    "                chars.append(f'</{e_type}>')\n",
    "            \n",
    "            # Insert opening tag\n",
    "            if start <= len(chars):\n",
    "                chars.insert(start, f'<{e_type}>')\n",
    "        \n",
    "        item['output'] = ''.join(chars)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def loaddata(filename):\n",
    "    \"\"\"\n",
    "    Read BIO format file (text_a\\tlabel format)\n",
    "    Automatically handle issues: character/label length mismatch, empty lines, format errors\n",
    "    Return data list structure consistent with original annotation\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    line_count = 0\n",
    "    success_count = 0\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            # Skip header\n",
    "            next(f)\n",
    "            \n",
    "            for line in f:\n",
    "                line_count += 1\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    print(f\"Skipping empty line (Line {line_count})\")\n",
    "                    continue\n",
    "                \n",
    "                # Split text and label by tab\n",
    "                try:\n",
    "                    text_part, label_part = line.split('\\t', 1)\n",
    "                except ValueError:\n",
    "                    print(f\"Format error (Line {line_count}): Missing tab separator\")\n",
    "                    continue\n",
    "                \n",
    "                # Parse text part (character-level splitting)\n",
    "                input_chars = text_part.split('\\002')\n",
    "                original_text = ''.join(input_chars)\n",
    "                \n",
    "                # Parse label part (BIO tag splitting)\n",
    "                bio_tags = label_part.split('\\002')\n",
    "                \n",
    "                # Length validation (prioritize valid sections)\n",
    "                min_len = min(len(input_chars), len(bio_tags))\n",
    "                if len(input_chars) != len(bio_tags):\n",
    "                    print(f\"Length mismatch warning (Line {line_count}): \"\n",
    "                          f\"Characters {len(input_chars)} vs Tags {len(bio_tags)}, truncated\")\n",
    "                    input_chars = input_chars[:min_len]\n",
    "                    bio_tags = bio_tags[:min_len]\n",
    "                \n",
    "                # Verify character and tag consistency\n",
    "                if ''.join(input_chars) != original_text[:min_len]:\n",
    "                    print(f\"Character misalignment warning (Line {line_count}): \"\n",
    "                          \"Split characters don't match original text, possible \\002 escape issue\")\n",
    "                \n",
    "                # Build data item\n",
    "                data_item = {\n",
    "                    'input': original_text,\n",
    "                    'label_BIO': '\\002'.join(bio_tags)\n",
    "                }\n",
    "                data.append(data_item)\n",
    "                success_count += 1\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {filename} not found\")\n",
    "        return []\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Error: File {filename} is not UTF-8 encoded\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Successfully read {success_count}/{line_count} valid records (Skipped {line_count - success_count} exceptions)\")\n",
    "    return data\n",
    "\n",
    "import re\n",
    "\n",
    "def delpkl(name):\n",
    "    for item in name:\n",
    "        output = item['output']\n",
    "        if '</think>' in output:\n",
    "            output = output.split('</think>')[1]\n",
    "        # Extract all time entities\n",
    "        times = re.findall(r'<time>(.*?)</time>', output)\n",
    "        # Extract all location entities\n",
    "        locations = re.findall(r'<Location>(.*?)</Location>', output)\n",
    "        # Extract all disaster entities\n",
    "        disasters = re.findall(r'<disaster>(.*?)</disaster>', output)\n",
    "        \n",
    "        item['label_json'] = {\n",
    "            'time': times,\n",
    "            'location': locations,\n",
    "            'disaster': disasters\n",
    "        }\n",
    "\n",
    "a = loaddata('./data_and_checkpoints/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cd0b23c-3a21-4f7b-9772-9eeb0898222f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "b = bio_to_tags(a)\n",
    "c = delpkl(b)\n",
    "# c\n",
    "with open(os.path.join('data_and_checkpoints',\"test.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(b, f)  \n",
    "print('The data was successfully saved as a pkl file.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
